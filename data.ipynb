{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "import dask.dataframe as dd\n",
    "from dask_ml.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_needed = ['date_id', 'time_id', 'symbol_id', 'weight', 'feature_00', 'feature_01',\n",
    "       'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06',\n",
    "       'feature_07', 'feature_08', 'feature_09', 'feature_10', 'feature_11',\n",
    "       'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16',\n",
    "       'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21',\n",
    "       'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26',\n",
    "       'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31',\n",
    "       'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36',\n",
    "       'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41',\n",
    "       'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46',\n",
    "       'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51',\n",
    "       'feature_52', 'feature_53', 'feature_54', 'feature_55', 'feature_56',\n",
    "       'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61',\n",
    "       'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66',\n",
    "       'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71',\n",
    "       'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76',\n",
    "       'feature_77', 'feature_78','responder_6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TO-do\n",
    "- Function to load datasets --> Use \n",
    "- Function to clean datasets\n",
    "- Function to train XGB \n",
    "- Function to train SVM\n",
    "    - Reduce data with PCA\n",
    "- Display data\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask Version \n",
    "\n",
    "# Load datasets to Dask dataframes\n",
    "def load_datasets(file_number):\n",
    "    file_path = f'/Users/elireadnour/Documents/Computer/Classes/machineLearning/MLFinal/jane-street-real-time-market-data-forecasting/train.parquet/partition_id={file_number}/part-0.parquet'\n",
    "    new_dataset = dd.read_parquet(file_path, columns=columns_needed)\n",
    "    return new_dataset\n",
    "\n",
    "# Load data using Dask\n",
    "data_0 = load_datasets(0)\n",
    "data_1 = load_datasets(1)\n",
    "data_2 = load_datasets(2)\n",
    "data_3 = load_datasets(3)\n",
    "data_4 = load_datasets(4)\n",
    "data_5 = load_datasets(5)\n",
    "data_6 = load_datasets(6)\n",
    "data_7 = load_datasets(7)\n",
    "data_8 = load_datasets(8)\n",
    "data_9 = load_datasets(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of training datasets\n",
    "training_datasets = [data_0,data_1,data_2,data_3, data_4, data_5, data_6, data_7, data_8, data_9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask Version \n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Load the Parquet file using PyArrow\n",
    "table = pq.read_table(\n",
    "    '/Users/elireadnour/Documents/Computer/Classes/machineLearning/MLFinal/jane-street-real-time-market-data-forecasting/lags.parquet/date_id=0/part-0.parquet'\n",
    ")\n",
    "\n",
    "# Convert PyArrow Table to a Pandas DataFrame and then to Dask\n",
    "lag_0_pandas = table.to_pandas()\n",
    "lag_0 = dd.from_pandas(lag_0_pandas, npartitions=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask Version \n",
    "def optimize_dtypes_dask(df):\n",
    "    # Convert float64 columns to float32\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    \n",
    "    # Convert int64 columns to int32\n",
    "    int_cols = df.select_dtypes(include=['int64']).columns\n",
    "    for col in int_cols:\n",
    "        df[col] = df[col].astype('int32')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Optimize Dask datasets\n",
    "data_0 = optimize_dtypes_dask(data_0)\n",
    "lag_0 = optimize_dtypes_dask(lag_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DASK VERSION  \n",
    "\n",
    "def get_lagged_data(previous_file, lag_column='responder_6', lag_name='responder_6_lag_1'):\n",
    "    # Extract only the necessary columns and rename for clarity\n",
    "    lagged_data = previous_file[['time_id', lag_column]].rename(columns={lag_column: lag_name})\n",
    "    return lagged_data\n",
    "\n",
    "def add_lags_to_next_file_dask(current_file, previous_file):\n",
    "    # Get lagged data from the previous file\n",
    "    lagged_data = get_lagged_data(previous_file)\n",
    "\n",
    "    # Merge the lagged data into the current file using only time_id\n",
    "    current_file = current_file.merge(lagged_data, on=['time_id'], how='left')\n",
    "\n",
    "    return current_file\n",
    "\n",
    "# Function to add lagged data to the current file\n",
    "'''def add_lags_to_next_file_dask(current_file, previous_file):\n",
    "    # Rename responder_6 in the previous file to avoid conflicts\n",
    "    previous_file = previous_file.rename(columns={'responder_6': 'responder_6_lag_1'})\n",
    "\n",
    "    # Drop existing lag column in the current file, if it exists\n",
    "    if 'responder_6_lag_1' in current_file.columns:\n",
    "        current_file = current_file.drop('responder_6_lag_1', axis=1)\n",
    "\n",
    "    # Merge the previous day's lagged responder_6 into the current file\n",
    "    current_file = current_file.merge(\n",
    "        previous_file[['time_id', 'responder_6_lag_1']],\n",
    "        on=['time_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    return current_file'''\n",
    "\n",
    "\n",
    "# Assuming `data_0` and `lag_0` are Dask DataFrames\n",
    "data_0 = data_0.merge(\n",
    "    lag_0[['time_id', 'responder_6_lag_1']],\n",
    "    on=['time_id'],\n",
    "    how='left'\n",
    ")\n",
    "training_datasets[0] = data_0\n",
    "\n",
    "# Iteratively add lag data to subsequent datasets\n",
    "for x in range(1, len(training_datasets)):\n",
    "    training_datasets[x] = add_lags_to_next_file_dask(training_datasets[x], training_datasets[x - 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual variables originally placed in the training datasets do not get changed. Once put in the list they are two different objects. Must reference the object via indexing the datasets list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responder_6_lag_1\n",
      "responder_6_lag_1\n",
      "responder_6_lag_1\n",
      "responder_6_lag_1\n",
      "responder_6_lag_1\n",
      "responder_6_lag_1\n",
      "responder_6_lag_1\n",
      "responder_6_lag_1\n",
      "responder_6_lag_1\n",
      "responder_6_lag_1\n"
     ]
    }
   ],
   "source": [
    "for x in training_datasets:\n",
    "    print(x.columns[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PICK UP HERE TOMORROW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>feature_00</th>\n",
       "      <th>feature_01</th>\n",
       "      <th>feature_02</th>\n",
       "      <th>feature_03</th>\n",
       "      <th>feature_04</th>\n",
       "      <th>feature_05</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>feature_75</th>\n",
       "      <th>feature_76</th>\n",
       "      <th>feature_77</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>responder_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.112212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.06033</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.249266</td>\n",
       "      <td>-0.353061</td>\n",
       "      <td>-0.944552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.218977</td>\n",
       "      <td>-0.304388</td>\n",
       "      <td>-0.272583</td>\n",
       "      <td>-0.421823</td>\n",
       "      <td>-0.044332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_id  time_id  symbol_id    weight  feature_00  feature_01  feature_02  \\\n",
       "0      170        0          0  2.112212         NaN         NaN         NaN   \n",
       "\n",
       "   feature_03  feature_04  feature_05  ...  feature_70  feature_71  \\\n",
       "0         NaN         NaN     1.06033  ...   -1.249266   -0.353061   \n",
       "\n",
       "   feature_72  feature_73  feature_74  feature_75  feature_76  feature_77  \\\n",
       "0   -0.944552         NaN         NaN   -0.218977   -0.304388   -0.272583   \n",
       "\n",
       "   feature_78  responder_6  \n",
       "0   -0.421823    -0.044332  \n",
       "\n",
       "[1 rows x 84 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Function to get and add lag files \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "values_for_lag = ['date_id', 'time_id', 'symbol_id','responder_6']\n",
    "\n",
    "def add_lags_to_next_file(current_file, previous_file):\n",
    "    # Rename responder_6 in the previous file to avoid conflicts\n",
    "    previous_file = previous_file.rename(columns={'responder_6': 'responder_6_lag_1'})\n",
    "    \n",
    "    # Merge the previous day's lagged responder_6 into the current file\n",
    "    current_file = current_file.merge(\n",
    "        previous_file[['time_id', 'symbol_id', 'responder_6_lag_1']],\n",
    "        on=['time_id', 'symbol_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Drop rows with NaN caused by lagging (optional)\n",
    "    current_file = current_file.dropna()\n",
    "\n",
    "    return current_file\n",
    "\n",
    "data_0 = data_0.merge(lag_0[['time_id', 'symbol_id','responder_6_lag_1']], on=['time_id', 'symbol_id'], how='left')\n",
    "\n",
    "for x in range(1,2):\n",
    "    add_lags_to_next_file(training_datasets[x],training_datasets[x-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_id', 'time_id', 'symbol_id', 'weight', 'feature_00', 'feature_01',\n",
       "       'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06',\n",
       "       'feature_07', 'feature_08', 'feature_09', 'feature_10', 'feature_11',\n",
       "       'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16',\n",
       "       'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21',\n",
       "       'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26',\n",
       "       'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31',\n",
       "       'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36',\n",
       "       'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41',\n",
       "       'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46',\n",
       "       'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51',\n",
       "       'feature_52', 'feature_53', 'feature_54', 'feature_55', 'feature_56',\n",
       "       'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61',\n",
       "       'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66',\n",
       "       'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71',\n",
       "       'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76',\n",
       "       'feature_77', 'feature_78', 'responder_0', 'responder_1', 'responder_2',\n",
       "       'responder_3', 'responder_4', 'responder_5', 'responder_6',\n",
       "       'responder_7', 'responder_8', 'responder_6_lag_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anonymize\n",
    "def anonymize(file): \n",
    "    pass\n",
    "    return file\n",
    "\n",
    "for x in training_datasets: \n",
    "    x = anonymize(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def scale_data(file):\n",
    "    scaled_X = scale.fit_transform(file)\n",
    "    return scaled_X\n",
    "\n",
    "\n",
    "# Split the data into training and testing se\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "scale = StandardScaler()\n",
    "\n",
    "def train_XGB(file,count):\n",
    "# Train the model\n",
    "    X = file.drop('responder_6', axis=1)\n",
    "    y = file['responder_6']\n",
    "\n",
    "    X_scaled = scale(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    '''mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'data_{count} accuracy = {mse}')'''\n",
    "\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    print(f\"MAPE: {mape}%\")\n",
    "\n",
    "    return xgb_model\n",
    "\n",
    "counter = 0\n",
    "for x in training_datasets: \n",
    "    train_XGB(x,counter)\n",
    "    counter +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error (or other relevant metrics)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (XGBoost): {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Validation MSE: 0.16485415697097777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Using 5-fold cross-validation for model validation\n",
    "kf_scores = cross_val_score(xgb_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Average Cross-Validation MSE: {-kf_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   7.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.8; total time=  11.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.8; total time=  13.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.8; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.8; total time=  15.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.8; total time=  17.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.8; total time=  15.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   8.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   8.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.8; total time=   8.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=300, subsample=0.6; total time=  27.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=300, subsample=0.6; total time=  30.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, min_child_weight=1, n_estimators=300, subsample=0.6; total time=  29.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=300, subsample=0.8; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=300, subsample=0.8; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=300, subsample=0.8; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1.0; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=500, subsample=0.8; total time=  31.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=500, subsample=0.8; total time=  33.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=500, subsample=0.8; total time=  32.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=7, n_estimators=100, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=7, n_estimators=100, subsample=0.8; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=7, n_estimators=100, subsample=0.8; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500, subsample=1.0; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500, subsample=1.0; total time=  14.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500, subsample=1.0; total time=  12.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   8.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=500, subsample=1.0; total time=  29.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=500, subsample=1.0; total time=  28.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=10, min_child_weight=3, n_estimators=500, subsample=1.0; total time=  29.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=500, subsample=1.0; total time=  13.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=500, subsample=1.0; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=500, subsample=1.0; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.8; total time=  17.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.8; total time=  17.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.8; total time=  18.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=7, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=7, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=7, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=300, subsample=0.8; total time=   8.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=300, subsample=0.8; total time=   7.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=300, subsample=0.8; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, min_child_weight=1, n_estimators=500, subsample=1.0; total time=  27.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, min_child_weight=1, n_estimators=500, subsample=1.0; total time=  27.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=10, min_child_weight=1, n_estimators=500, subsample=1.0; total time=  28.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=7, min_child_weight=3, n_estimators=100, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500, subsample=1.0; total time=  12.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500, subsample=1.0; total time=  12.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=500, subsample=1.0; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=500, subsample=0.8; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=500, subsample=0.8; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, min_child_weight=3, n_estimators=500, subsample=0.8; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.6; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   9.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   9.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=300, subsample=1.0; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=500, subsample=1.0; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=500, subsample=1.0; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=500, subsample=1.0; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=100, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, min_child_weight=7, n_estimators=100, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, min_child_weight=7, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, min_child_weight=7, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, min_child_weight=7, n_estimators=500, subsample=0.8; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, min_child_weight=7, n_estimators=500, subsample=0.8; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, min_child_weight=7, n_estimators=500, subsample=0.8; total time=  12.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.8; total time=   8.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.8; total time=   8.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.8; total time=   8.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=7, n_estimators=300, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=7, n_estimators=300, subsample=0.8; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, min_child_weight=7, n_estimators=300, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.6; total time=  16.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.6; total time=  17.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.6; total time=  17.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, subsample=0.6; total time=  31.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, subsample=0.6; total time=  30.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, subsample=0.6; total time=  32.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=100, subsample=0.6; total time=   8.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=100, subsample=0.6; total time=   8.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, min_child_weight=7, n_estimators=100, subsample=0.6; total time=   9.9s\n",
      "Best Parameters: {'subsample': 1.0, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(XGBRegressor(objective='reg:squarederror'), param_distributions=param_dist, n_iter=30, cv=2, scoring='neg_mean_squared_error', verbose=2, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned XGB Model using parameters from Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "final_xgb_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    subsample=1.0,\n",
    "    n_estimators=500,\n",
    "    min_child_weight=3,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    colsample_bytree=0.6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on the training data\n",
    "final_xgb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "final_xgb_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    subsample=1.0,\n",
    "    n_estimators=500,\n",
    "    min_child_weight=3,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    colsample_bytree=0.6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on the training data\n",
    "final_xgb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Final Model): 0.10424154996871948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = final_xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (Final Model): {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Validation MSE: 0.1558243989944458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Using 5-fold cross-validation for model validation\n",
    "kf_scores = cross_val_score(final_xgb_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Average Cross-Validation MSE: {-kf_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing: Standard Scaller "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "\n",
    "X = scale.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10730664 0.20812827 0.27430323 0.3348844  0.38985676 0.44306043\n",
      " 0.4930155  0.5316344  0.5646317  0.5944145  0.62315035 0.6516101\n",
      " 0.67846054 0.70308244 0.7267795  0.7499029  0.7708257  0.7903909\n",
      " 0.8078895  0.8237381  0.8393095  0.8532956  0.86696416 0.88004553\n",
      " 0.8927529  0.9019354  0.9109082  0.9195607  0.92790073 0.9355657\n",
      " 0.9425222  0.9482943  0.9533449 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)  # Automaticall collect enough features to caputre 95 % of variance\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "print(cumulative_variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB w/PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (XGBoost): 0.32325002551078796\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb_model1 = XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_model1.fit(X_train1, y_train1)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred1 = xgb_model1.predict(X_test1)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error (or other relevant metrics)\n",
    "mse1 = mean_squared_error(y_test1, y_pred1)\n",
    "print(f\"Mean Squared Error (XGBoost): {mse1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Using 5-fold cross-validation for model validation\n",
    "kf_scores = cross_val_score(xgb_model, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Average Cross-Validation MSE: {-kf_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git add .\n",
    "# git commit -m \"commit message\"\n",
    "# git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "- Heat maps Variance\n",
    "- XGBoost --> Finds most highly correlated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "- Heat maps Variance\n",
    "- XGBoost --> Finds most highly correlated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
